"use strict";(self.webpackChunksf_documentation=self.webpackChunksf_documentation||[]).push([[7120],{3905:function(e,n,a){a.d(n,{Zo:function(){return k},kt:function(){return d}});var t=a(7294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function i(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=t.createContext({}),s=function(e){var n=t.useContext(p),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},k=function(e){var n=s(e.components);return t.createElement(p.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,k=i(e,["components","mdxType","originalType","parentName"]),u=s(a),d=r,c=u["".concat(p,".").concat(d)]||u[d]||m[d]||o;return a?t.createElement(c,l(l({ref:n},k),{},{components:a})):t.createElement(c,l({ref:n},k))}));function d(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=a.length,l=new Array(o);l[0]=u;var i={};for(var p in n)hasOwnProperty.call(n,p)&&(i[p]=n[p]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=a[s];return t.createElement.apply(null,l)}return t.createElement.apply(null,a)}u.displayName="MDXCreateElement"},1539:function(e,n,a){a.r(n),a.d(n,{frontMatter:function(){return i},contentTitle:function(){return p},metadata:function(){return s},toc:function(){return k},default:function(){return u}});var t=a(7462),r=a(3366),o=(a(7294),a(3905)),l=["components"],i={},p="Monitoring Kafka Clusters running in Kubernetes",s={unversionedId:"Integrations/kafka/kafka_kubernetes",id:"Integrations/kafka/kafka_kubernetes",isDocsHomePage:!1,title:"Monitoring Kafka Clusters running in Kubernetes",description:"Kafka on Kubernetes can be monitored in SnappyFlow using two approaches:",source:"@site/docs/Integrations/kafka/kafka_kubernetes.md",sourceDirName:"Integrations/kafka",slug:"/Integrations/kafka/kafka_kubernetes",permalink:"/docs/Integrations/kafka/kafka_kubernetes",editUrl:"https://github.com/ram-dot-kumar/SFwebsite.git/docs/Integrations/kafka/kafka_kubernetes.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"overview",permalink:"/docs/Integrations/kafka/overview"},next:{title:"Monitoring Kafka Clusters running on Instances",permalink:"/docs/Integrations/kafka/kafka_instances"}},k=[{value:"Kafka monitoring with sfKubeAgent",id:"kafka-monitoring-with-sfkubeagent",children:[{value:"Prerequisites",id:"prerequisites",children:[]},{value:"Configuration Parameters Breakdown",id:"configuration-parameters-breakdown",children:[]},{value:"Viewing data and dashboards",id:"viewing-data-and-dashboards",children:[]}]},{value:"<strong>Kafka monitoring with</strong> Prometheus:",id:"kafka-monitoring-with-prometheus",children:[{value:"Prerequisites",id:"prerequisites-1",children:[]},{value:"Documents",id:"documents",children:[]},{value:"Viewing data and dashboards",id:"viewing-data-and-dashboards-1",children:[]}]}],m={toc:k};function u(e){var n=e.components,a=(0,r.Z)(e,l);return(0,o.kt)("wrapper",(0,t.Z)({},m,a,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"monitoring-kafka-clusters-running-in-kubernetes"},"Monitoring Kafka Clusters running in Kubernetes"),(0,o.kt)("h1",{id:"overview"},"Overview"),(0,o.kt)("p",null,"Kafka on Kubernetes can be monitored in SnappyFlow using two approaches:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("a",{parentName:"p",href:"/docs/Integrations/kubernetes/sfkubeagent_installation"},"sfKubeAgent")," as sidecar container.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("a",{parentName:"p",href:"/docs/Integrations/kubernetes/prometheus_exporter"},"Prometheus exporter")))),(0,o.kt)("h2",{id:"kafka-monitoring-with-sfkubeagent"},"Kafka monitoring with sfKubeAgent"),(0,o.kt)("h3",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"sfKubeAgent container is run as a side-car n Kafka Pod")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Init-Container: sfKubeAgent plugin requires Jolokia to be run with the Kafka process. Jolokia exposes mbeans over default port 8778. Jolokia can be downloaded using init-container from the below url: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"https://repo1.maven.org/maven2/org/jolokia/jolokia-jvm/1.6.2/jolokia-jvm-1.6.2-agent.jar\n")),(0,o.kt)("p",{parentName:"li"},"Both Confluent and Apache distributions allow Java agents to be started along with Kafka process. To start Jolokia along with the Kafka broker , set environment variable KAFKA_JMX_OPTS along with Configured agent mount path in broker\u2019s container.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"The value of Kafka-JMX-OPTS must be as below:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'- name: KAFKA_JMX_OPTS\n  value: "-javaagent:/agent/jolokia.jar=port=8778,host=127.0.0.1 \n          -Djava.rmi.server.hostname=127.0.0.1 \n          -Dcom.sun.management.jmxremote=true \n          -Dcom.sun.management.jmxremote.authenticate=false  \n          -Dcom.sun.management.jmxremote.ssl=false"\n')),(0,o.kt)("p",{parentName:"li"},"Sample Init Container Configuration for including Jolokia"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"initContainers:\n- name: get-jolokia\n  image: alpine\n  command:\n  - sh\n  - -c\n  - -x\n  - apk add --no-cache curl && curl ${JOLOKIA_JAR_URL} -o /agent/jolokia.jar\n  env:\n  - name: JOLOKIA_JAR_URL\n    value: https://repo1.maven.org/maven2/org/jolokia/jolokia-jvm/1.6.2/jolokia-jvm-1.6.2-agent.jar\n  volumeMounts:\n  - name: javaagentdir\n    mountPath: /agent\n")))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Kafka Pod yaml:")),(0,o.kt)("p",null,"Example of the Kafka Pod.yaml is below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\n\nmetadata:  \n  labels:\n    snappyflow/appname: <application_name>\n    snappyflow/projectname: <project_name>\n    name: kafka-pod\nspec:  \n  containers:\n  - command:\n    - sh\n    - -exc\n    - |\n      export KAFKA_BROKER_ID=${HOSTNAME##*-} && \\\n      export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-pod.kafka-sfagent-kafka-sfagent-headless.default:9092,EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID})) && \\\n      exec /etc/confluent/docker/run\n\n    env:    \n    - name: KAFKA_JMX_OPTS\n      value: -javaagent:/agent/jolokia.jar=port=8778,host=127.0.0.1 -Djava.rmi.server.hostname=127.0.0.1\n        -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false\n    image: mahendra0939/kafka-auditable:latest\n    imagePullPolicy: IfNotPresent\n\n    name: kafka-broker\n    ports:\n    - containerPort: 9092\n      name: kafka\n      protocol: TCP\n    - containerPort: 8778\n      name: jolokia\n      protocol: TCP\n\n    volumeMounts:\n    - mountPath: /opt/kafka/data\n      name: datadir\n    - mountPath: /etc/customlog4j\n      name: connect-log4j-properties\n    - mountPath: /var/log/kafka\n      name: varlog\n    - mountPath: /agent\n      name: javaagentdir\n      readOnly: true\n\n  - command:\n    - /app/sfagent\n    - -enable-console-log\n    env:\n    - name: APP_NAME\n      value: <application_name>\n    - name: PROJECT_NAME\n      value: <project_name>\n    image: snappyflowml/sfagent:latest\n    imagePullPolicy: Always\n\n    name: sfagent\n    volumeMounts:\n    - mountPath: /var/log/kafka\n      name: varlog\n    - mountPath: /opt/sfagent/config.yaml\n      name: sfagent-config-kafka\n      subPath: config.yaml\n      readOnly: true\n\n  initContainers:\n  - command:\n    - sh\n    - -c\n    - -x\n    - apk add --no-cache curl && curl ${JOLOKIA_JAR_URL} -o /agent/jolokia.jar\n\n    env:\n    - name: JOLOKIA_JAR_URL\n      value: https://repo1.maven.org/maven2/org/jolokia/jolokia-jvm/1.6.2/jolokia-jvm-1.6.2-agent.jar\n    image: alpine\n    imagePullPolicy: Always\n\n    name: get-jolokia \n    volumeMounts:\n    - mountPath: /agent\n      name: javaagentdir\n      readOnly: true\n\n  volumes:\n  - emptyDir: {}\n    name: datadir    \n  - emptyDir: {}\n    name: javaagentdir\n  - emptyDir: {}\n    name: varlog\n  - configMap:\n      defaultMode: 420\n      name: kafka-sfkubeagent-configmap\n    name: sfagent-config-kafka\n  - configMap:\n      defaultMode: 420\n      name: kafka-configmap\n    name: connect-log4j-properties\n\n")),(0,o.kt)("p",null,"In addition to the pod.yaml below config-map for sfkubeAgent container and Kafka container."),(0,o.kt)("p",null,"Example for the config-map are below:"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Kafka config map:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'apiVersion: v1\nkind: ConfigMap\nmetadata:  \n  name: kafka-configmap\ndata:\n  connect-log4j.properties: "log4j.rootLogger=INFO, kafkaAppender\\nlog4j.appender.kafkaAppender.File=/var/log/kafka/server.log\\nlog4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.kafkaAppender.layout.ConversionPattern=[%d]\n    %p %m (%c)%n\\nlog4j.appender.kafkaAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.kafkaAppender.MaxFileSize=5MB\\nlog4j.appender.kafkaAppender.MaxBackupIndex=5\\nlog4j.appender.stateChangeAppender.File=/var/log/kafka/state-change.log\\nlog4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\n    \\   \\nlog4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\\nlog4j.appender.stateChangeAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.stateChangeAppender.MaxFileSize=5MB\\nlog4j.appender.stateChangeAppender.MaxBackupIndex=5\\ng4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender\\nlog4j.appender.requestAppender.File=/var/log/kafka/kafka-request.log\\nlog4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.requestAppender.layout.ConversionPattern=[%d]\n    %p %m (%c)%n\\nlog4j.appender.requestAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.requestAppender.MaxFileSize=5MB\\nlog4j.appender.requestAppender.MaxBackupIndex=5\\nlog4j.appender.cleanerAppender.File=/logs/log-cleaner.log\\nlog4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.cleanerAppender.layout.ConversionPattern=[%d]\n    %p %m (%c)%n\\nlog4j.appender.cleanerAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.cleanerAppender.MaxFileSize=5MB\\nlog4j.appender.cleanerAppender.MaxBackupIndex=5\\nlog4j.appender.controllerAppender.File=/var/log/kafka/controller.log\\nlog4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.controllerAppender.layout.ConversionPattern=[%d]\n    %p %m (%c)%n\\nlog4j.appender.controllerAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.controllerAppender.MaxFileSize=5MB\\nlog4j.appender.controllerAppender.MaxBackupIndex=5\\nlog4j.appender.authorizerAppender.File=/var/log/kafka/kafka-authorizer.log\\nlog4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\\nlog4j.appender.authorizerAppender.layout.ConversionPattern=[%d]\n    %p %m (%c)%n\\nlog4j.appender.authorizerAppender=org.apache.log4j.RollingFileAppender\\nlog4j.appender.authorizerAppender.MaxFileSize=5MB\\nlog4j.appender.authorizerAppender.MaxBackupIndex=5\\n\nlog4j.logger.kafka=INFO\\nlog4j.logger.org.apache.kafka=INFO\\n\nlog4j.logger.kafka.request.logger=WARN,\n    requestAppender\\nlog4j.additivity.kafka.request.logger=false\\n \nlog4j.logger.kafka.network.RequestChannel$=WARN,\n    requestAppender\\nlog4j.additivity.kafka.network.RequestChannel$=false\\nlog4j.logger.kafka.controller=TRACE,\n    controllerAppender\\nlog4j.additivity.kafka.controller=false\\nlog4j.logger.kafka.log.LogCleaner=INFO,\n    cleanerAppender\\nlog4j.additivity.kafka.log.LogCleaner=false\\nlog4j.logger.state.change.logger=TRACE,\n    stateChangeAppender\\nlog4j.additivity.state.change.logger=false\\n \n\\nlog4j.logger.kafka.authorizer.logger=DEBUG,\n    authorizerAppender\\nlog4j.additivity.kafka.authorizer.logger=false\\n"\n\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Config map for Kafka sfKubeAgent:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'apiVersion: v1\nkind: ConfigMap\nmetadata:  \n  labels:\n    app.kubernetes.io/managed-by: Helm\n    snappyflow/appname: <application_name>\n    snappyflow/projectname: <project_name>\n  name: kafka-sfkubeagent-configmap\ndata:\n  config.yaml: |\n    ---\n    key: "<Profile_key>\u201d\n    logging:\n      plugins:\n      - name: kafka-general\n        enabled: true\n        config:\n          log_level:\n            - error\n            - info\n            - debug\n            - warn\n            - notice\n          log_path: /var/log/kafka/server.log,/var/log/kafka/state-change.log,/var/log/kafka/kafka-request.log,/var/log/kafka/controller.log,/var/log/kafka/kafka-authorizer.log\n\n    metrics:\n      plugins:\n      - name: kube-sfagent-kafkatopic\n        enabled: true\n        interval: 300\n        config:\n          documentsTypes:\n            - kafkaStats\n            - partitionStats\n            - topicStats\n            - consumerStats\n          jolokiaPort: 8778\n          RMIPort: 8778\n          jolokiaContext: jolokia\n          jolokiaProtocol: http\n          jolokiaProxy: false\n          port: 9092\n          process: kafka.Kafka,io.confluent.support.metrics.SupportedKafka \n \n      - name: kube-sfagent-kafkajmx\n        enabled: true\n        interval: 300\n        config:\n          process: kafka.Kafka,io.confluent.support.metrics.SupportedKafka\n          jolokiaPort: 8778\n          RMIPort: 8778\n          jolokiaContext: jolokia\n          jolokiaProtocol: http\n          jolokiaProxy: false\n\n')),(0,o.kt)("p",null,"Plugin Type ",(0,o.kt)("inlineCode",{parentName:"p"},"kafkatopic")," consists of documents organized into following types"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"Kafka stats"),": contain transactional data and metrics related to broker state")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"Topic stats"),":  provide metrics for analyzing internal transactions associated with each     topic")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"Partition stats"),": provide log size and segment information for each partition")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"Consumer stats"),": provide consumer lag and offset information"),(0,o.kt)("p",{parentName:"li"},"Plugin Type ",(0,o.kt)("inlineCode",{parentName:"p"},"kafkajmx")," contains single type of document")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"JVM stats"),": contain all JVM related metrics like garbage collection details, memory     pools, loaded/unloaded classes etc."))),(0,o.kt)("h3",{id:"configuration-parameters-breakdown"},"Configuration Parameters Breakdown"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"jolokiaPort"),": port on which jolokia based requests are served"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"jolokiaContext"),": context makes jolokia endpoint. Default value is string"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"jolokiaProtocol"),": request/response protocol"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"jolokiaProxy"),": jolokia proxy mode, if enabled for Jolokia agent"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"RMIPort"),": RMI port. if enabled"),(0,o.kt)("h3",{id:"viewing-data-and-dashboards"},"Viewing data and dashboards"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Metric data generated by plugin can be viewed in ",(0,o.kt)("inlineCode",{parentName:"p"},"browse data")," page inside the respective application under metrics section with plugin= ",(0,o.kt)("inlineCode",{parentName:"p"},"kube-sfagent-kafkajmx")," and documentType= ",(0,o.kt)("inlineCode",{parentName:"p"},"jmxStats"),". Data from topics can be found in metrics section with plugin= ",(0,o.kt)("inlineCode",{parentName:"p"},"kube-sfagent-kafkatopic")," and documentType= ",(0,o.kt)("inlineCode",{parentName:"p"},"consumerStats")," , ",(0,o.kt)("inlineCode",{parentName:"p"},"kafkaStats"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"partitionStats")," , ",(0,o.kt)("inlineCode",{parentName:"p"},"topicStats"),".")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Dashboard for this data can be instantiated by Importing dashboard template ",(0,o.kt)("inlineCode",{parentName:"p"},"Kafka_Kube_SF")," to the application dashboard"),(0,o.kt)("p",{parentName:"li"},"For help with plugins, please reach out to ",(0,o.kt)("a",{parentName:"p",href:"mailto:support@snappyflow.io"},"support@snappyflow.io"),"."))),(0,o.kt)("h2",{id:"kafka-monitoring-with-prometheus"},(0,o.kt)("strong",{parentName:"h2"},"Kafka monitoring with")," Prometheus:"),(0,o.kt)("p",null,"Refer to ",(0,o.kt)("a",{parentName:"p",href:"/docs/Integrations/kubernetes/prometheus_exporter"},"Prometheus Exporter Overview")," to understand how SnappyFlow monitors using Prometheus exporters. "),(0,o.kt)("h3",{id:"prerequisites-1"},"Prerequisites"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Enabling JMX Monitoring")),(0,o.kt)("p",{parentName:"li"},"JMX monitoring needs to be enabled for the kafka process. Following properties need to be set for the process."),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"-Dcom.sun.management.jmxremote\n-Djava.rmi.server.hostname=0.0.0.0 \n-Dcom.sun.management.jmxremote.local.only=false \n-Dcom.sun.management.jmxremote.port= userDefinedJMXPort \n-Dcom.sun.management.jmxremote.rmi.port= userDefinedJMXPort \n-Dcom.sun.management.jmxremote.authenticate=false \n-Dcom.sun.management.jmxremote.ssl=false\n"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Prometheus JMX exporter Integration"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"Docker Image: solsson/kafka-prometheus-jmx-exporter@sha256\nImage Tag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8\n")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Configuration:")," Exporter needs to be deployed as one of the containers in broker pods and following command needs to be executed as the actual container process"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"java -jar jmx_prometheus_httpserver.jar userDefinedPrometheusPort configurationFile\n")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Instrumentation"),": Prometheus instrumentation is based on the exporter rules specified in exporterConfigurationFile. Config File needs to be mounted with following contents"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:userDefinedJMXPort/jmxrmi\nlowercaseOutputName: true\nlowercaseOutputLabelNames: true\nssl: false\n\nwhitelistObjectNames: ["kafka.controller:*","kafka.server:*","java.lang:*","kafka.network:*","kafka.log:*"]\n\nrules:\n- pattern: kafka.controller<type=(ControllerChannelManager), name=(QueueSize), broker-id=(\\d+)><>(Value)\n  name: kafka_controller_$1_$2_$4\n  labels:\n  broker_id: "$3"\n- pattern: kafka.controller<type=(ControllerChannelManager), name=(TotalQueueSize)><>(Value)\n  name: kafka_controller_$1_$2_$3\n- pattern: kafka.controller<type=(KafkaController), name=(.+)><>(Value)\n  name: kafka_controller_$1_$2_$3\n- pattern: kafka.controller<type=(ControllerStats), name=(.+)><>(Count|OneMinuteRate)\n  name: kafka_controller_$1_$2_$3\n- pattern: kafka.server<type=(ReplicaFetcherManager), name=(.+), clientId=(.+)><>(Value)\n  name: kafka_server_$1_$2_$4\n  labels:\n    client_id: "$3"\n- pattern : kafka.network<type=(Processor), name=(IdlePercent), networkProcessor=(.+)><>(Value)\n  name: kafka_network_$1_$2_$4\n  labels:\n    network_processor: $3\n- pattern : kafka.network<type=(RequestMetrics), name=(.+), request=([^,]+).*><>(Count|OneMinuteRate|Mean)\n  name: kafka_network_$1_$2_$4\n  labels:\n    request: $3\n- pattern: kafka.server<type=(.+), name=(.+), topic=(.+)><>(Count|OneMinuteRate)\n  name: kafka_server_$1_$2_$4\n  labels:\n    topic: $3\n- pattern: kafka.server<type=(DelayedOperationPurgatory), name=(.+), delayedOperation=(.+)><>(Value)\n  name: kafka_server_$1_$2_$3_$4\n- pattern: kafka.server<type=(.+), name=(.+)><>(Count|Value|OneMinuteRate)\n  name: kafka_server_$1_total_$2_$3\n- pattern: kafka.server<type=(.+)><>(queue-size)\n  name: kafka_server_$1_$2\n- pattern: java.lang<type=(.+), name=(.+)><(.+)>(\\w+)\n  name: java_lang_$1_$4_$3_$2\n- pattern: java.lang<type=(.+), name=(.+)><>(\\w+)\n  name: java_lang_$1_$3_$2\n- pattern : java.lang<type=(.*)>\n- pattern: kafka.log<type=(.+), name=(.+), topic=(.+), partition=(.+)><>Value\n  name: kafka_log_$1_$2\n  labels:\n    topic: $3\n    partition: $4\n')),(0,o.kt)("div",{parentName:"li",className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"By default, confluent and apache kafka helm charts ships with the JMX exporter. In these charts , JMX port will be set to 5555 by default .Exporter rules and whitelisted objects only needs to be updated with the above specified Instrumentation in the configuration file."))),(0,o.kt)("p",{parentName:"li"},"Kubernetes service needs to be created for exposing ",(0,o.kt)("em",{parentName:"p"},"userDefinedPrometheusPort")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Reference:")," ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/prometheus/jmx_exporter/blob/master/README.md"},"Prometheus JMX exporter"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Danielqs Exporter"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"Docker Image: danielqsj/kafka-exporter\nImage Tag: v1.0.1\n")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Configuration:")," Exporter is installed as a container in separate pod. Kafka broker details and prometheus listener port needs to be configured in following way"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"- args:\n  - --kafka.server= brokerhost:brokerPort\n  - --web.listen-address=:userDefinedPrometheusListenerPort\n")),(0,o.kt)("p",{parentName:"li"},"Kubernetes service needs to be created for exposing ",(0,o.kt)("em",{parentName:"p"},"userDefinedPrometheusListenerPort")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Reference:")," ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/danielqsj/kafka_exporter/blob/master/README.md"},"Danielqs Exporter")))),(0,o.kt)("h3",{id:"documents"},"Documents"),(0,o.kt)("p",null,"Plugin Type ",(0,o.kt)("inlineCode",{parentName:"p"},"kube-prom-kafka-jmx")," contains the metrics organized into following document types"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"Kafka stats"),": contain transactional data and metrics related to broker state"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"Topic stats"),": provide metrics for analyzing internal transactions associated with each     topic"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"Partition stats"),": provide log size information for each partition"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"jmx stats"),": contain all JVM related metrics like garbage collection details,     memory pools, loaded/unloaded classes etc.")),(0,o.kt)("p",null,"Plugin Type ",(0,o.kt)("inlineCode",{parentName:"p"},"kube-prom-kafka")," contains the metrics organized into following document types"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"Consumer stats"),": Contains consumers related information and the total partiton count.")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Configmap for kafka Prometheus")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'apiVersion: v1\nkind: ConfigMap\nmetadata:  \n  name: kafka-prom-configmap\ndata:\n  jmx-kafka-prometheus.yml: |\n    jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi\n    lowercaseOutputName: true\n    lowercaseOutputLabelNames: true\n    ssl: false\n\n    whitelistObjectNames: ["kafka.controller:*","kafka.server:*","java.lang:*","kafka.network:*","kafka.log:*"]\n\n    rules:\n    - pattern: kafka.controller<type=(ControllerChannelManager), name=(QueueSize), broker-id=(\\d+)><>(Value)\n      name: kafka_controller_$1_$2_$4\n      labels:\n        broker_id: "$3"\n    - pattern: kafka.controller<type=(ControllerChannelManager), name=(TotalQueueSize)><>(Value)\n      name: kafka_controller_$1_$2_$3\n    - pattern: kafka.controller<type=(KafkaController), name=(.+)><>(Value)\n      name: kafka_controller_$1_$2_$3\n    - pattern: kafka.controller<type=(ControllerStats), name=(.+)><>(Count|OneMinuteRate)\n      name: kafka_controller_$1_$2_$3\n    - pattern: kafka.server<type=(ReplicaFetcherManager), name=(.+), clientId=(.+)><>(Value)\n      name: kafka_server_$1_$2_$4\n      labels:\n        client_id: "$3"\n    - pattern : kafka.network<type=(Processor), name=(IdlePercent), networkProcessor=(.+)><>(Value)\n      name: kafka_network_$1_$2_$4\n      labels:\n        network_processor: $3\n    - pattern : kafka.network<type=(RequestMetrics), name=(.+), request=([^,]+).*><>(Count|OneMinuteRate|Mean)\n      name: kafka_network_$1_$2_$4\n      labels:\n        request: $3\n    - pattern: kafka.server<type=(.+), name=(.+), topic=(.+)><>(Count|OneMinuteRate)\n      name: kafka_server_$1_$2_$4\n      labels:\n        topic: $3\n    - pattern: kafka.server<type=(DelayedOperationPurgatory), name=(.+), delayedOperation=(.+)><>(Value)\n      name: kafka_server_$1_$2_$3_$4\n    - pattern: kafka.server<type=(.+), name=(.+)><>(Count|Value|OneMinuteRate)\n      name: kafka_server_$1_total_$2_$3\n    - pattern: kafka.server<type=(.+)><>(queue-size)\n      name: kafka_server_$1_$2\n    - pattern: java.lang<type=(.+), name=(.+)><(.+)>(\\w+)\n      name: java_lang_$1_$4_$3_$2\n    - pattern: java.lang<type=(.+), name=(.+)><>(\\w+)\n      name: java_lang_$1_$3_$2\n    - pattern : java.lang<type=(.*)>\n    - pattern: kafka.log<type=(.+), name=(.+), topic=(.+), partition=(.+)><>Value\n      name: kafka_log_$1_$2\n      labels:\n        topic: $3\n        partition: $4\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Kafka Service YAML")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    snappyflow/appname: <application_name>\n    snappyflow/plugin: kafka-jmx\n    snappyflow/projectname: <project_name>\n  name: kafka-prom-service\n  ports:\n  - name: broker\n    port: 9092\n    protocol: TCP\n    targetPort: 9092\n  - name: jmx-exporter\n    port: 5555\n    protocol: TCP\n    targetPort: 5556\n  - name: kafka-exporter\n    port: 9308\n    protocol: TCP\n    targetPort: 9308\n  type: ClusterIP\n")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Kafka Pod YAML")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  labels:   \n    snappyflow/appname: <application_name>\n    snappyflow/component: kafka\n    snappyflow/projectname: <project_name>    \n  name: kafka-prom-pod\nspec:\n  containers:\n  - command:\n    - java\n    - -XX:+UnlockExperimentalVMOptions\n    - -XX:+UseCGroupMemoryLimitForHeap\n    - -XX:MaxRAMFraction=1\n    - -XshowSettings:vm\n    - -jar\n    - jmx_prometheus_httpserver.jar\n    - "5556"\n    - /etc/jmx-kafka/jmx-kafka-prometheus.yml\n    image: solsson/kafka-prometheus-jmx-exporter@sha256:a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8\n    imagePullPolicy: IfNotPresent\n    name: metrics\n    ports:\n    - containerPort: 5556\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /etc/jmx-kafka\n      name: jmx-config\n      readOnly: true\n\n  - command:\n    - sh\n    - -exc\n    - |\n      export KAFKA_BROKER_ID=${HOSTNAME##*-} && \\\n      export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_NAME}.kafka-prom-kafka-headless.${POD_NAMESPACE}:9092,EXTERNAL://${HOST_IP}:$((31090 + ${KAFKA_BROKER_ID})) && \\\n      exec /etc/confluent/docker/run\n    env:\n    - name: JMX_PORT\n      value: "5555"\n    - name: KAFKA_JMX_OPTS\n      value: -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false\n    image: mahendra0939/kafka-auditable:latest\n    imagePullPolicy: IfNotPresent\n    livenessProbe:\n      exec:\n        command:\n        - sh\n        - -ec\n        - /usr/bin/jps | /bin/grep -q SupportedKafka\n    name: kafka-broker\n    ports:\n    - containerPort: 9092\n      name: kafka\n      protocol: TCP\n    - containerPort: 8778\n      name: jolokia\n      protocol: TCP\n    - containerPort: 5555\n      name: jmx\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /opt/kafka/data\n      name: datadir\n    - mountPath: /var/log/kafka\n      name: varlog\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: kafka-prom-token-s8fmp\n      readOnly: true\n\n  - args:\n    - --kafka.server=kafka-prom-service:9092\n    - --web.listen-address=:9308\n    image: danielqsj/kafka-exporter:v1.0.1\n    imagePullPolicy: IfNotPresent\n    name: kafka-exporter\n    ports:\n    - containerPort: 9308\n      protocol: TCP\n    volumeMounts:\n    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n      name: default-token-lv29f\n      readOnly: true  \n\n  volumes:\n  - name: datadir\n    persistentVolumeClaim:\n      claimName: datadir-kafka-prom-kafka-0\n  - emptyDir: {}\n    name: varlog\n  - configMap:\n      defaultMode: 420\n      name: kafka-prom-configmap\n    name: jmx-config\n  - name: default-token-lv29f\n    secret:\n      defaultMode: 420\n      secretName: default-token-lv29f\n')),(0,o.kt)("h3",{id:"viewing-data-and-dashboards-1"},"Viewing data and dashboards"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Data generated by plugin can be viewed in ",(0,o.kt)("inlineCode",{parentName:"li"},"browse data")," page inside the respective application under plugin= ",(0,o.kt)("inlineCode",{parentName:"li"},"kube-prom-kafka")," and documentType= ",(0,o.kt)("inlineCode",{parentName:"li"},"consumerStats")," . JMX Data can be found in metrics section with plugin= kube-prom-kafka-jmx and documentType= ",(0,o.kt)("inlineCode",{parentName:"li"},"jmxStats")," , ",(0,o.kt)("inlineCode",{parentName:"li"},"kafkaStats"),", ",(0,o.kt)("inlineCode",{parentName:"li"},"partitionStats")," , ",(0,o.kt)("inlineCode",{parentName:"li"},"topicStats"),"."),(0,o.kt)("li",{parentName:"ul"},"Dashboard for this data can be instantiated by Importing dashboard template ",(0,o.kt)("inlineCode",{parentName:"li"},"Kafka_Kube_Prom")," to the application dashboard")),(0,o.kt)("p",null,"For help with plugins, please reach out to ",(0,o.kt)("a",{parentName:"p",href:"mailto:support@snappyflow.io"},"support@snappyflow.io"),"."))}u.isMDXComponent=!0}}]);